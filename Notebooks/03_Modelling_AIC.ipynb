{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Type\n",
    "\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn.metrics import mean_squared_error as mse\n",
    "# from splot.libpysal import plot_spatial_weights\n",
    "import prince\n",
    "import scipy.stats as stats\n",
    "\n",
    "# from splot.esda import moran_scatterplot\n",
    "import seaborn as sns\n",
    "import statsmodels\n",
    "import statsmodels.api as sm\n",
    "from pysal.lib import weights\n",
    "\n",
    "# from pysal.explore import esda\n",
    "# from pysal.viz import splot\n",
    "from pysal.model import spreg\n",
    "\n",
    "# from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from splot.esda import moran_scatterplot\n",
    "from statsmodels.graphics.gofplots import ProbPlot, qqplot\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import maybe_unwrap_results\n",
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "%matplotlib inline\n",
    "os.environ[\"USE_PYGEOS\"] = \"0\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling (AIC)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Data Preparation for Modelling\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading and Transforming Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_pickle(\"../Data/all_data.piclo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filtro de outliers, calculados ao longo das regressões realizadas no notebook 3 (Modelling) e adicionado ao longo do processo\n",
    "# # (linha acima foram usadas para atualizar esta lista até o retorno de um conjunto vazio)\n",
    "# # a cada \"run\" do notebook, esta lista deve ser atualizada com os outliers identificados\n",
    "# # parou-se de atualizar a lista quando o conjunto de outliers começou, repetidamente, a devolver apenas 2 ou 3 outliers\n",
    "\n",
    "# run 1 - 13 outliers\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 563242]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 1177680]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 1131818]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2383113]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2568707]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2639959]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2632030]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2870116]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2743956]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2939163]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2953594]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2939578]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 3089766]\n",
    "\n",
    "# run 2 - 12 outliers\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 563276]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 1254649]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 1253964]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2251268]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2569071]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2644045]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2631437]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2712461]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2696442]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2939264]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2811941]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 3161153]\n",
    "\n",
    "# run 3 - 12 outliers\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 563391]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 1235755]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 1247318]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2380527]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2569178]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2638746]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2629208]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2718713]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2875618]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2687064]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 2958943]\n",
    "all_data = all_data.loc[all_data[\"ID\"] != 3120730]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Cluster_LP\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[all_data.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion of data\n",
    "all_data[\"Year\"] = all_data[\"Year\"].astype(\"int64\")\n",
    "all_data[\"Cluster_LP\"] = all_data[\"Cluster_LP\"].astype(\"int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"T\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a=set(outliers_sum)\n",
    "# all_data.loc[list(a)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"T\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Year\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores do Indice de Preços da Habitação para Aveiro (valores para 21, 22 e 23 são previsões, com base na tendência dos últimos anos)\n",
    "IPI2005 = 116.5\n",
    "IPI2006 = 110.9\n",
    "IPI2007 = 114.3\n",
    "IPI2008 = 109.4\n",
    "IPI2009 = 103.1\n",
    "IPI2010 = 104.4\n",
    "IPI2018 = 100.8\n",
    "IPI2019 = 114.2\n",
    "IPI2020 = 126.2\n",
    "IPI2021 = 132.1\n",
    "IPI2022 = 133.7\n",
    "IPI2023 = 135.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write IPI values to new column\n",
    "def new_column_value(Year):\n",
    "    if Year == 2005:\n",
    "        return IPI2005\n",
    "    elif Year == 2006:\n",
    "        return IPI2006\n",
    "    elif Year == 2007:\n",
    "        return IPI2007\n",
    "    elif Year == 2008:\n",
    "        return IPI2008\n",
    "    elif Year == 2009:\n",
    "        return IPI2009\n",
    "    elif Year == 2010:\n",
    "        return IPI2010\n",
    "    elif Year == 2018:\n",
    "        return IPI2018\n",
    "    elif Year == 2019:\n",
    "        return IPI2019\n",
    "    elif Year == 2020:\n",
    "        return IPI2020\n",
    "    elif Year == 2021:\n",
    "        return IPI2021\n",
    "    elif Year == 2022:\n",
    "        return IPI2022\n",
    "    elif Year == 2023:\n",
    "        return IPI2023\n",
    "\n",
    "\n",
    "all_data[\"IPI\"] = all_data[\"Year\"].apply(new_column_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores da Taxa Anual de juro (TAA) de novos empréstimos à habitação (BdP)\n",
    "TAA2005 = 3.38\n",
    "TAA2006 = 4.01\n",
    "TAA2007 = 4.8\n",
    "TAA2008 = 5.44\n",
    "TAA2009 = 2.73\n",
    "TAA2010 = 2.47\n",
    "TAA2018 = 1.41\n",
    "TAA2019 = 1.22\n",
    "TAA2020 = 1\n",
    "TAA2021 = 0.81\n",
    "TAA2022 = 1.82\n",
    "TAA2023 = 3.76"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write IPI values to new column\n",
    "def new_column_value(Year):\n",
    "    if Year == 2005:\n",
    "        return TAA2005\n",
    "    elif Year == 2006:\n",
    "        return TAA2006\n",
    "    elif Year == 2007:\n",
    "        return TAA2007\n",
    "    elif Year == 2008:\n",
    "        return TAA2008\n",
    "    elif Year == 2009:\n",
    "        return TAA2009\n",
    "    elif Year == 2010:\n",
    "        return TAA2010\n",
    "    elif Year == 2018:\n",
    "        return TAA2018\n",
    "    elif Year == 2019:\n",
    "        return TAA2019\n",
    "    elif Year == 2020.0:\n",
    "        return TAA2020\n",
    "    elif Year == 2021.0:\n",
    "        return TAA2021\n",
    "    elif Year == 2022:\n",
    "        return TAA2022\n",
    "    elif Year == 2023:\n",
    "        return TAA2023\n",
    "\n",
    "\n",
    "all_data[\"TAA\"] = all_data[\"Year\"].apply(new_column_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## poucos valores para os anos 2023 e 2005 (início de uma base de dados e fim da outra - serão removidos)\n",
    "\n",
    "all_data = all_data.loc[all_data[\"Year\"] != 2023]\n",
    "all_data = all_data.loc[all_data[\"Year\"] != 2005]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(all_data[[\"Tot_AL\", \"IPI\", \"TAA\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "all_data[a] = StandardScaler().fit_transform(all_data[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 MCA for Intrinsic Features\n",
    "\n",
    "https://maxhalford.github.io/prince/mca/ - Multiple correspondence analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"Typology\", \"Nature\", \"Status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n",
    "# OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca = prince.MCA(\n",
    "    n_components=10,\n",
    "    n_iter=3,\n",
    "    copy=True,\n",
    "    check_input=True,\n",
    "    engine=\"sklearn\",\n",
    "    random_state=42,\n",
    ")\n",
    "mca.fit(all_data[a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.eigenvalues_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mca.column_contributions_.style.format(\"{:.0%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PC_values = np.arange(mca.n_components) + 1\n",
    "plt.plot(\n",
    "    PC_values,\n",
    "    [17.15, 11.88, 10.52, 10.11, 10, 10, 9.88, 9.30, 8.06, 3.10],\n",
    "    \"o-\",\n",
    "    linewidth=2,\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.axhline(10.14, color=\"green\", linestyle=\"--\", linewidth=1)\n",
    "plt.title(\"Scree Plot\")\n",
    "plt.xlabel(\"Componentes Principais\")\n",
    "plt.ylabel(\"Variancia Explicada\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"MCA_1\"] = mca.transform(all_data[a])[0]\n",
    "all_data[\"MCA_2\"] = mca.transform(all_data[a])[1]\n",
    "all_data[\"MCA_3\"] = mca.transform(all_data[a])[2]\n",
    "all_data[\"MCA_4\"] = mca.transform(all_data[a])[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Generate Discriptive Statistics HTML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[\"Nature\"] = all_data[\"Nature\"].astype(\"category\")\n",
    "all_data[\"Typology\"] = all_data[\"Typology\"].astype(\"category\")\n",
    "all_data[\"Status\"] = all_data[\"Status\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the report - Final\n",
    "\n",
    "all_data_analysis = all_data.copy()\n",
    "all_data_analysis = all_data_analysis[\n",
    "    [\"Log_P_A\", \"MCA_1\", \"MCA_2\", \"MCA_3\", \"MCA_4\", \"TAA\", \"IPI\", \"Tot_AL\"]\n",
    "]\n",
    "profile = ProfileReport(\n",
    "    all_data_analysis,\n",
    "    title=\"AIC Data Profile Report\",\n",
    "    explorative=True,\n",
    "    config_file=\"../Data/config_default.yaml\",\n",
    ")\n",
    "profile.to_notebook_iframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the report to .html\n",
    "profile.to_file(\"AIC_Data_Profile_Report_MCA.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get min, max, mean, std dev for the dataset\n",
    "\n",
    "all_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.describe()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Create GeoDataFrames with all_data + different territorial limits (Freguesias, Skater Cluster, Cluster LP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.1 Create GeoDataFrames with all_data + Cluster_LP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_LP = pd.read_pickle(\"../Data/piclo_clusters_2.piclo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_LP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cluster_LP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = all_data[~all_data[\"Cluster_LP\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge dwelling data with clusters data\n",
    "all_data_LP = all_data.merge(Cluster_LP, on=\"Cluster_LP\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns\n",
    "all_data_LP.drop(\n",
    "    columns=[\n",
    "        \"PCA_1\",\n",
    "        \"PCA_2\",\n",
    "        \"PCA_3\",\n",
    "        \"PCA_4\",\n",
    "        \"PCA_5\",\n",
    "        \"PCA_6\",\n",
    "        \"PCA_7\",\n",
    "        \"PCA_8\",\n",
    "        \"PCA_9\",\n",
    "        \"PCA_10\",\n",
    "        \"PCA_11\",\n",
    "        \"PCA_12\",\n",
    "        \"PCA_13\",\n",
    "        \"PCA_14\",\n",
    "        \"PCA_15\",\n",
    "        \"PCA_16\",\n",
    "        \"PCA_17\",\n",
    "        \"tot_cs\",\n",
    "        \"tot_py\",\n",
    "        \"tot_min\",\n",
    "        \"Price\",\n",
    "    ],\n",
    "    axis=1,\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop dwellings with no lat lon information (geometry)\n",
    "all_data_LP2 = all_data_LP[all_data_LP[\"geometry\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP2[\"geometry\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP2[\"Cluster_LP\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop dwellings with no lat lon information (geometry)\n",
    "all_data_LP = all_data_LP[~all_data_LP[\"geometry\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = all_data_LP[all_data_LP[\"T\"] == 1]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data_LP[\"Cluster_LP\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertion of data to float\n",
    "all_data_LP[\"Zona_Ward\"] = np.floor(\n",
    "    pd.to_numeric(all_data_LP[\"Zona_Ward\"], errors=\"coerce\")\n",
    ").astype(\"float64\")\n",
    "all_data_LP[\"Zona_Ward_Queen\"] = np.floor(\n",
    "    pd.to_numeric(all_data_LP[\"Zona_Ward_Queen\"], errors=\"coerce\")\n",
    ").astype(\"float64\")\n",
    "all_data_LP[\"Zona_Maxp\"] = np.floor(\n",
    "    pd.to_numeric(all_data_LP[\"Zona_Maxp\"], errors=\"coerce\")\n",
    ").astype(\"float64\")\n",
    "all_data_LP[\"Zona_SKATER\"] = np.floor(\n",
    "    pd.to_numeric(all_data_LP[\"Zona_SKATER\"], errors=\"coerce\")\n",
    ").astype(\"float64\")\n",
    "all_data_LP[\"Cluster_LP\"] = np.floor(\n",
    "    pd.to_numeric(all_data_LP[\"Cluster_LP\"], errors=\"coerce\")\n",
    ").astype(\"float64\")\n",
    "all_data_LP[\"Year\"] = np.floor(\n",
    "    pd.to_numeric(all_data_LP[\"Year\"], errors=\"coerce\")\n",
    ").astype(\"float64\")\n",
    "all_data_LP[\"T\"] = np.floor(pd.to_numeric(all_data_LP[\"T\"], errors=\"coerce\")).astype(\n",
    "    \"float64\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_LP[\"geometry\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.2 Create GeoDataFrames with all_data + Skater\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater = all_data_LP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater = gpd.GeoDataFrame(all_data_skater, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater_geo = all_data_skater.dissolve(by=\"Zona_SKATER\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater_geo = all_data_skater_geo[[\"Zona_SKATER\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater = all_data_skater.merge(\n",
    "    all_data_skater_geo, on=\"Zona_SKATER\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.drop(columns=[\"geometry_x\"], axis=1, inplace=True)\n",
    "all_data_skater.rename(columns={\"geometry_y\": \"geometry\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater = gpd.GeoDataFrame(all_data_skater, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater = all_data_skater[~all_data_skater[\"Cluster_LP\"].isnull()]\n",
    "all_data_skater = all_data_skater[~all_data_skater[\"Zona_SKATER\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data_skater[\"Zona_SKATER\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater[\"geometry\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_skater[\"Year\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4.3 Create GeoDataFrames with all_data + FR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr = all_data_LP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to geodataframe\n",
    "all_data_fr = gpd.GeoDataFrame(all_data_fr, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr.plot(\n",
    "    column=\"Cluster_LP\", categorical=True, legend=False, figsize=(10, 10), cmap=\"tab20c\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_FR = pd.read_pickle(\"../Data/piclo_clusters_fr.piclo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_FR.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_LP = pd.read_pickle(\"../Data/piclo_clusters_lp.piclo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_LP.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_LP[\"geometry2\"] = CLUSTER_LP.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_LP.rename(\n",
    "    columns={\"geometry\": \"geometry2\", \"geometry2\": \"geometry\"}, inplace=True\n",
    ")\n",
    "CLUSTER_LP.drop(columns=[\"geometry2\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER_LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER = CLUSTER_FR.sjoin(CLUSTER_LP, how=\"inner\", predicate=\"intersects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER[\"Cluster_LP\"] = CLUSTER[\"Cluster_LP\"].astype(\"float64\")\n",
    "CLUSTER[\"FR11\"] = CLUSTER[\"FR11\"].astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLUSTER = CLUSTER[[\"Cluster_LP\", \"FR11\", \"geometry\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr = all_data_fr.merge(CLUSTER, on=\"Cluster_LP\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr.drop(columns=[\"geometry_x\"], axis=1, inplace=True)\n",
    "all_data_fr.rename(columns={\"geometry_y\": \"geometry\"}, inplace=True)\n",
    "all_data_fr = all_data_fr[~all_data_fr[\"Cluster_LP\"].isnull()]\n",
    "all_data_fr = all_data_fr[~all_data_fr[\"Zona_SKATER\"].isnull()]\n",
    "all_data_fr = all_data_fr[~all_data_fr[\"FR11\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_fr[\"geometry\"].nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Linear Regressions (Aveiro) - SKATER\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Data Preparation for DID Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to geodataframe\n",
    "data_aveiro_skater = gpd.GeoDataFrame(all_data_skater, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater[\"T\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view Zona_SKATER clusters\n",
    "ax = data_aveiro_skater.plot(\n",
    "    figsize=(10, 10),\n",
    "    column=\"Zona_SKATER\",\n",
    "    categorical=True,\n",
    "    edgecolor=\"w\",\n",
    "    legend=True,\n",
    "    linewidth=0.2,\n",
    "    cmap=\"tab20\",\n",
    ")\n",
    "cx.add_basemap(ax, crs=data_aveiro_skater.crs, source=cx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply above list to data\n",
    "data_aveiro_skater[\"D\"] = np.where(\n",
    "    (data_aveiro_skater[\"Zona_SKATER\"] == 3.0)\n",
    "    | (data_aveiro_skater[\"Zona_SKATER\"] == 6.0)\n",
    "    | (data_aveiro_skater[\"Zona_SKATER\"] == 7.0),\n",
    "    1,\n",
    "    0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check no. of dwellings per cluster in Aveiro Center\n",
    "pd.pivot_table(\n",
    "    data_aveiro_skater,\n",
    "    values=\"Log_P_A\",\n",
    "    index=[\"Zona_SKATER\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ").head(10)\n",
    "# não incluir cluster 80, 102 e 106, por escassez de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater.to_pickle(\"../Data/data_aveiro_skater.piclo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater[\"D\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data_aveiro_skater[data_aveiro_skater[\"D\"] == 0]\n",
    "a[[\"Log_P_A\", \"Tot_AL\", \"TAA\", \"IPI\", \"MCA_1\", \"MCA_2\", \"MCA_3\", \"MCA_4\"]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_aveiro_skater[\"D\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result of the SKATER Regionalization\n",
    "ax = data_aveiro_skater.plot(\n",
    "    figsize=(10, 10),\n",
    "    column=data_aveiro_skater[\"D\"],\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    linewidth=0.1,\n",
    "    cmap=\"tab20\",\n",
    ")\n",
    "cx.add_basemap(ax, crs=data_aveiro_skater.crs, source=cx.providers.OpenStreetMap.Mapnik)\n",
    "ax.set_title(\n",
    "    \"Treatment Group (1) and Control Group (0)\", fontweight=\"bold\", fontsize=16\n",
    ")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check areas defined as control and intervention areas (D=0 and D=1)\n",
    "ax = data_aveiro_skater.plot(\n",
    "    column=data_aveiro_skater[\"D\"],\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    figsize=(10, 10),\n",
    "    cmap=\"tab20\",\n",
    ")\n",
    "plt.title(\"Zona de Intervenção (1) e Zona de Controlo (0)\")\n",
    "cx.add_basemap(ax, crs=data_aveiro_skater.crs, source=cx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate DT (true when both D and T are equal to 1)\n",
    "data_aveiro_skater[\"DT\"] = data_aveiro_skater[\"D\"] * data_aveiro_skater[\"T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater[\"DT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check log_P_A distribution in the territory\n",
    "ax = data_aveiro_skater.plot(\n",
    "    column=np.exp(data_aveiro_skater[\"Log_P_A\"]),\n",
    "    legend=True,\n",
    "    figsize=(10, 10),\n",
    "    cmap=\"viridis\",\n",
    "    scheme=\"quantiles\",\n",
    "    k=6,\n",
    "    linewidth=0.3,\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Preço médio dos imóveis (€/m2), por Cluster (SKATER)\")\n",
    "cx.add_basemap(ax, crs=data_aveiro_skater.crs, source=cx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Linear Regression (focused in Aveiro Center - SKATER Cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_skater,\n",
    "    values=\"Log_P_A\",\n",
    "    index=[\"Zona_SKATER\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_skater, values=\"DT\", index=[\"Zona_SKATER\"], aggfunc=\"sum\"\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_skater,\n",
    "    values=\"Zona_SKATER\",\n",
    "    index=[\"D\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for skater zones\n",
    "data_aveiro_skater_ols = pd.get_dummies(\n",
    "    data_aveiro_skater, columns=[\"Zona_SKATER\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_ols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "c_y_eur_area_skater = data_aveiro_skater_ols[\"Log_P_A\"].astype(float)\n",
    "\n",
    "c_X_eur_area_skater = data_aveiro_skater_ols[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"TAA\",\n",
    "        \"Zona_SKATER_1.0\",\n",
    "        \"Zona_SKATER_2.0\",\n",
    "        \"Zona_SKATER_3.0\",\n",
    "        \"Zona_SKATER_4.0\",\n",
    "        \"Zona_SKATER_5.0\",\n",
    "        \"Zona_SKATER_6.0\",\n",
    "        \"Zona_SKATER_7.0\",\n",
    "        \"Zona_SKATER_8.0\",\n",
    "    ]\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model for casasapo with log of price per square meter as dependent variable\n",
    "c_X_eur_area_skater = sm.add_constant(c_X_eur_area_skater)\n",
    "model_c_eur_area_skater = sm.OLS(c_y_eur_area_skater, c_X_eur_area_skater)\n",
    "results_c_eur_area_skater = model_c_eur_area_skater.fit()\n",
    "skater_save = results_c_eur_area_skater.summary2()\n",
    "results_c_eur_area_skater.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export results to csv\n",
    "# skater_save.tables[0].to_csv('skater_0.csv')\n",
    "# skater_save.tables[1].to_csv('skater_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base code for diagnostic plots\n",
    "\n",
    "style_talk = \"seaborn-talk\"  # refer to plt.style.available\n",
    "\n",
    "\n",
    "class Linear_Reg_Diagnostic:\n",
    "    \"\"\"\n",
    "    Diagnostic plots to identify potential problems in a linear regression fit.\n",
    "    Mainly,\n",
    "        a. non-linearity of data\n",
    "        b. Correlation of error terms\n",
    "        c. non-constant variance\n",
    "        d. outliers\n",
    "        e. high-leverage points\n",
    "        f. collinearity\n",
    "\n",
    "    Author:\n",
    "        Prajwal Kafle (p33ajkafle@gmail.com, where 3 = r)\n",
    "        Does not come with any sort of warranty.\n",
    "        Please test the code one your end before using.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        results: Type[statsmodels.regression.linear_model.RegressionResultsWrapper],\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        For a linear regression model, generates following diagnostic plots:\n",
    "\n",
    "        a. residual\n",
    "        b. qq\n",
    "        c. scale location and\n",
    "        d. leverage\n",
    "\n",
    "        and a table\n",
    "\n",
    "        e. vif\n",
    "\n",
    "        Args:\n",
    "            results (Type[statsmodels.regression.linear_model.RegressionResultsWrapper]):\n",
    "                must be instance of statsmodels.regression.linear_model object\n",
    "\n",
    "        Raises:\n",
    "            TypeError: if instance does not belong to above object\n",
    "\n",
    "        Example:\n",
    "        >>> import numpy as np\n",
    "        >>> import pandas as pd\n",
    "        >>> import statsmodels.formula.api as smf\n",
    "        >>> x = np.linspace(-np.pi, np.pi, 100)\n",
    "        >>> y = 3*x + 8 + np.random.normal(0,1, 100)\n",
    "        >>> df = pd.DataFrame({'x':x, 'y':y})\n",
    "        >>> res = smf.ols(formula= \"y ~ x\", data=df).fit()\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls(plot_context=\"seaborn-paper\")\n",
    "\n",
    "        In case you do not need all plots you can also independently make an individual plot/table\n",
    "        in following ways\n",
    "\n",
    "        >>> cls = Linear_Reg_Diagnostic(res)\n",
    "        >>> cls.residual_plot()\n",
    "        >>> cls.qq_plot()\n",
    "        >>> cls.scale_location_plot()\n",
    "        >>> cls.leverage_plot()\n",
    "        >>> cls.vif_table()\n",
    "        \"\"\"\n",
    "\n",
    "        if (\n",
    "            isinstance(\n",
    "                results, statsmodels.regression.linear_model.RegressionResultsWrapper\n",
    "            )\n",
    "            is False\n",
    "        ):\n",
    "            raise TypeError(\n",
    "                \"result must be instance of statsmodels.regression.linear_model.RegressionResultsWrapper object\"\n",
    "            )\n",
    "\n",
    "        self.results = maybe_unwrap_results(results)\n",
    "\n",
    "        self.y_true = self.results.model.endog\n",
    "        self.y_predict = self.results.fittedvalues\n",
    "        self.xvar = self.results.model.exog\n",
    "        self.xvar_names = self.results.model.exog_names\n",
    "\n",
    "        self.residual = np.array(self.results.resid)\n",
    "        influence = self.results.get_influence()\n",
    "        self.residual_norm = influence.resid_studentized_internal\n",
    "        self.leverage = influence.hat_matrix_diag\n",
    "        self.cooks_distance = influence.cooks_distance[0]\n",
    "        self.nparams = len(self.results.params)\n",
    "\n",
    "    def __call__(self, plot_context=\"seaborn-v0_8-paper\"):\n",
    "        # print(plt.style.available)\n",
    "        with plt.style.context(plot_context):\n",
    "            fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10, 10))\n",
    "            self.residual_plot(ax=ax[0, 0])\n",
    "            self.qq_plot(ax=ax[0, 1])\n",
    "            self.scale_location_plot(ax=ax[1, 0])\n",
    "            self.leverage_plot(ax=ax[1, 1])\n",
    "            plt.show()\n",
    "\n",
    "        self.vif_table()\n",
    "        return fig, ax\n",
    "\n",
    "    def residual_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Residual vs Fitted Plot\n",
    "\n",
    "        Graphical tool to identify non-linearity.\n",
    "        (Roughly) Horizontal red line is an indicator that the residual has a linear pattern\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        sns.residplot(\n",
    "            x=self.y_predict,\n",
    "            y=self.residual,\n",
    "            lowess=True,\n",
    "            scatter_kws={\"alpha\": 0.5},\n",
    "            line_kws={\"color\": \"red\", \"lw\": 1, \"alpha\": 0.8},\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # annotations\n",
    "        residual_abs = np.abs(self.residual)\n",
    "        abs_resid = np.flip(np.sort(residual_abs))\n",
    "        abs_resid_top_3 = abs_resid[:3]\n",
    "        for i, _ in enumerate(abs_resid_top_3):\n",
    "            ax.annotate(i, xy=(self.y_predict[i], self.residual[i]), color=\"C3\")\n",
    "\n",
    "        ax.set_title(\"Residuals vs Fitted\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Fitted values\")\n",
    "        ax.set_ylabel(\"Residuals\")\n",
    "        return ax\n",
    "\n",
    "    def qq_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Standarized Residual vs Theoretical Quantile plot\n",
    "\n",
    "        Used to visually check if residuals are normally distributed.\n",
    "        Points spread along the diagonal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        QQ = ProbPlot(self.residual_norm)\n",
    "        QQ.qqplot(line=\"45\", alpha=0.5, lw=1, ax=ax)\n",
    "\n",
    "        # annotations\n",
    "        abs_norm_resid = np.flip(np.argsort(np.abs(self.residual_norm)), 0)\n",
    "        abs_norm_resid_top_3 = abs_norm_resid[:3]\n",
    "        for r, i in enumerate(abs_norm_resid_top_3):\n",
    "            ax.annotate(\n",
    "                i,\n",
    "                xy=(np.flip(QQ.theoretical_quantiles, 0)[r], self.residual_norm[i]),\n",
    "                ha=\"right\",\n",
    "                color=\"C3\",\n",
    "            )\n",
    "\n",
    "        ax.set_title(\"Normal Q-Q\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Theoretical Quantiles\")\n",
    "        ax.set_ylabel(\"Standardized Residuals\")\n",
    "        return ax\n",
    "\n",
    "    def scale_location_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Sqrt(Standarized Residual) vs Fitted values plot\n",
    "\n",
    "        Used to check homoscedasticity of the residuals.\n",
    "        Horizontal line will suggest so.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        residual_norm_abs_sqrt = np.sqrt(np.abs(self.residual_norm))\n",
    "\n",
    "        ax.scatter(self.y_predict, residual_norm_abs_sqrt, alpha=0.5)\n",
    "        sns.regplot(\n",
    "            x=self.y_predict,\n",
    "            y=residual_norm_abs_sqrt,\n",
    "            scatter=False,\n",
    "            ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={\"color\": \"red\", \"lw\": 1, \"alpha\": 0.8},\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # annotations\n",
    "        abs_sq_norm_resid = np.flip(np.argsort(residual_norm_abs_sqrt), 0)\n",
    "        abs_sq_norm_resid_top_3 = abs_sq_norm_resid[:3]\n",
    "        for i in abs_sq_norm_resid_top_3:\n",
    "            ax.annotate(\n",
    "                i, xy=(self.y_predict[i], residual_norm_abs_sqrt[i]), color=\"C3\"\n",
    "            )\n",
    "        ax.set_title(\"Scale-Location\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Fitted values\")\n",
    "        ax.set_ylabel(r\"$\\sqrt{|\\mathrm{Standardized\\ Residuals}|}$\")\n",
    "        return ax\n",
    "\n",
    "    def leverage_plot(self, ax=None):\n",
    "        \"\"\"\n",
    "        Residual vs Leverage plot\n",
    "\n",
    "        Points falling outside Cook's distance curves are considered observation that can sway the fit\n",
    "        aka are influential.\n",
    "        Good to have none outside the curves.\n",
    "        \"\"\"\n",
    "        if ax is None:\n",
    "            fig, ax = plt.subplots()\n",
    "\n",
    "        ax.scatter(self.leverage, self.residual_norm, alpha=0.5)\n",
    "        sns.regplot(\n",
    "            x=self.leverage,\n",
    "            y=self.residual_norm,\n",
    "            scatter=False,\n",
    "            ci=False,\n",
    "            lowess=True,\n",
    "            line_kws={\"color\": \"red\", \"lw\": 1, \"alpha\": 0.8},\n",
    "            ax=ax,\n",
    "        )\n",
    "\n",
    "        # annotations\n",
    "        leverage_top_3 = np.flip(np.argsort(self.cooks_distance), 0)[:3]\n",
    "        for i in leverage_top_3:\n",
    "            ax.annotate(i, xy=(self.leverage[i], self.residual_norm[i]), color=\"C3\")\n",
    "\n",
    "        xtemp, ytemp = self.__cooks_dist_line(0.5)  # 0.5 line\n",
    "        ax.plot(xtemp, ytemp, label=\"Cook's distance\", lw=1, ls=\"--\", color=\"red\")\n",
    "        xtemp, ytemp = self.__cooks_dist_line(1)  # 1 line\n",
    "        ax.plot(xtemp, ytemp, lw=1, ls=\"--\", color=\"red\")\n",
    "\n",
    "        ax.set_xlim(0, max(self.leverage) + 0.01)\n",
    "        ax.set_title(\"Residuals vs Leverage\", fontweight=\"bold\")\n",
    "        ax.set_xlabel(\"Leverage\")\n",
    "        ax.set_ylabel(\"Standardized Residuals\")\n",
    "        ax.legend(loc=\"upper right\")\n",
    "        return ax\n",
    "\n",
    "    def vif_table(self):\n",
    "        \"\"\"\n",
    "        VIF table\n",
    "\n",
    "        VIF, the variance inflation factor, is a measure of multicollinearity.\n",
    "        VIF > 5 for a variable indicates that it is highly collinear with the\n",
    "        other input variables.\n",
    "        \"\"\"\n",
    "        vif_df = pd.DataFrame()\n",
    "        vif_df[\"Features\"] = self.xvar_names\n",
    "        vif_df[\"VIF Factor\"] = [\n",
    "            variance_inflation_factor(self.xvar, i) for i in range(self.xvar.shape[1])\n",
    "        ]\n",
    "\n",
    "        print(vif_df.sort_values(\"VIF Factor\").round(2))\n",
    "\n",
    "    def __cooks_dist_line(self, factor):\n",
    "        \"\"\"\n",
    "        Helper function for plotting Cook's distance curves\n",
    "        \"\"\"\n",
    "        p = self.nparams\n",
    "        formula = lambda x: np.sqrt((factor * p * (1 - x)) / x)\n",
    "        x = np.linspace(0.001, max(self.leverage), 50)\n",
    "        y = formula(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostics for the model\n",
    "cls = Linear_Reg_Diagnostic(results_c_eur_area_skater)\n",
    "fig, ax = cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = results_c_eur_area_skater.outlier_test()\n",
    "# print('Bad data points (bonf(p) < 0.05):')\n",
    "# test[test['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers = test[test['bonf(p)'] < 0.05].index.values\n",
    "# outliers_sum=list(outliers)\n",
    "# all_data.loc[list(outliers)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Difference in Difference validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data for the model (DID validation)\n",
    "data_aveiro_skater_DID = data_aveiro_skater.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_DID[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_DID = data_aveiro_skater_DID[data_aveiro_skater_DID[\"T\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_DID[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_skater_DID,\n",
    "    values=\"Log_P_A\",\n",
    "    index=[\"Year\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy for year on the DT zone\n",
    "for i in data_aveiro_skater_DID[\"Year\"].unique():\n",
    "    data_aveiro_skater_DID[\"Year\" + str(i)] = np.where(\n",
    "        data_aveiro_skater_DID[\"Year\"] == i, data_aveiro_skater_DID[\"D\"], 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_DID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_skater_DID,\n",
    "    values=\"Log_P_A\",\n",
    "    index=[\"Zona_SKATER\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for skater zones\n",
    "data_aveiro_skater_DID = pd.get_dummies(\n",
    "    data_aveiro_skater_DID, columns=[\"Zona_SKATER\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dependent variable and independent variables\n",
    "\n",
    "DID_y_eur_area_skater = data_aveiro_skater_DID[\"Log_P_A\"].astype(float)\n",
    "\n",
    "DID_X_eur_area_skater = data_aveiro_skater_DID[\n",
    "    [\n",
    "        \"Year2006.0\",\n",
    "        \"Year2007.0\",\n",
    "        \"Year2008.0\",\n",
    "        \"Year2009.0\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"Zona_SKATER_1.0\",\n",
    "        \"Zona_SKATER_2.0\",\n",
    "        \"Zona_SKATER_3.0\",\n",
    "        \"Zona_SKATER_4.0\",\n",
    "        \"Zona_SKATER_5.0\",\n",
    "        \"Zona_SKATER_6.0\",\n",
    "        \"Zona_SKATER_7.0\",\n",
    "        \"Zona_SKATER_8.0\",\n",
    "        \"Tot_AL\",\n",
    "        \"IPI\",\n",
    "        \"TAA\",\n",
    "    ]\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model\n",
    "DID_X_eur_area_skater = sm.add_constant(DID_X_eur_area_skater)\n",
    "model_DID_eur_area_skater = sm.OLS(DID_y_eur_area_skater, DID_X_eur_area_skater)\n",
    "results_DID_eur_area_skater = model_DID_eur_area_skater.fit()\n",
    "DID_skater_save = results_DID_eur_area_skater.summary2()\n",
    "results_DID_eur_area_skater.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export results to csv\n",
    "# DID_skater_save.tables[0].to_csv('DID_skater_0.csv')\n",
    "# DID_skater_save.tables[1].to_csv('DID_skater_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostics for the model\n",
    "cls = Linear_Reg_Diagnostic(results_DID_eur_area_skater)\n",
    "fig, ax = cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = results_DID_eur_area_skater.outlier_test()\n",
    "# print('Bad data points (bonf(p) < 0.05):')\n",
    "# test[test['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers = test[test['bonf(p)'] < 0.05].index.values\n",
    "# outliers_sum=outliers_sum+list(outliers)\n",
    "# all_data.loc[list(outliers)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Spatial Linear Regression (focused in Aveiro Center - SKATER Cluster)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust = data_aveiro_skater.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração da matriz W, a partir do subset, usando a de matriz de contiguidade Queen\n",
    "w_Queen_skater = weights.contiguity.Queen.from_dataframe(data_aveiro_skater_Robust)\n",
    "# Standardização das linhas\n",
    "w_Queen_skater.transform = \"R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma resultante da metodologia matriz Queen para pesos espaciais\n",
    "pd.Series(w_Queen_skater.cardinalities).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_Queen_skater.mean_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image saved - this function is heavy and slows down the notebook\n",
    "# plot_spatial_weights(w_Queen_skater, data_aveiro_skater_Robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data_aveiro_skater_Robust.plot(\n",
    "    column=\"Zona_SKATER\", categorical=True, legend=True, figsize=(10, 10), cmap=\"tab20c\"\n",
    ")\n",
    "cx.add_basemap(\n",
    "    ax, crs=data_aveiro_skater_Robust.crs, source=cx.providers.OpenStreetMap.Mapnik\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply above list to data\n",
    "data_aveiro_skater_Robust[\"D\"] = np.where(\n",
    "    (data_aveiro_skater_Robust[\"Zona_SKATER\"] == 3.0)\n",
    "    | (data_aveiro_skater_Robust[\"Zona_SKATER\"] == 6.0)\n",
    "    | (data_aveiro_skater_Robust[\"Zona_SKATER\"] == 7.0),\n",
    "    1,\n",
    "    0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust[\"D\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_aveiro_skater_Robust[\"D\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate DT (true when both D and T are equal to 1)\n",
    "data_aveiro_skater_Robust[\"DT\"] = (\n",
    "    data_aveiro_skater_Robust[\"D\"] * data_aveiro_skater_Robust[\"T\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust[\"DT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data_aveiro_skater_Robust[\"Log_P_A\"]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(0.367561)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysal.explore import esda\n",
    "\n",
    "moran = esda.moran.Moran(data_aveiro_skater_Robust[\"Log_P_A\"], w_Queen_skater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran.I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moran_l = esda.moran.Moran_Local(data_aveiro_skater_Robust[\"Log_P_A\"], w_Queen_skater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysal.viz import splot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figura, ax = moran_scatterplot(moran_l, p=0.05)\n",
    "ax.set_title(\"Moran Scatterplot\")\n",
    "ax.set_xlabel(\"mediana_preço_hab\")\n",
    "ax.set_ylabel(\"Spatial Lag of mediana_preço_hab\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust[\"MCA_1_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_skater, data_aveiro_skater_Robust[\"MCA_1\"]\n",
    ")\n",
    "data_aveiro_skater_Robust[\"MCA_2_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_skater, data_aveiro_skater_Robust[\"MCA_2\"]\n",
    ")\n",
    "data_aveiro_skater_Robust[\"MCA_3_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_skater, data_aveiro_skater_Robust[\"MCA_3\"]\n",
    ")\n",
    "data_aveiro_skater_Robust[\"MCA_4_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_skater, data_aveiro_skater_Robust[\"MCA_4\"]\n",
    ")\n",
    "data_aveiro_skater_Robust[\"Tot_AL_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_skater, data_aveiro_skater_Robust[\"Tot_AL\"]\n",
    ")\n",
    "data_aveiro_skater_Robust[\"Log_P_A_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_skater, data_aveiro_skater_Robust[\"Log_P_A\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for skater zones\n",
    "data_aveiro_skater_Robust = pd.get_dummies(\n",
    "    data_aveiro_skater_Robust, columns=[\"Zona_SKATER\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de dataframe com variável dependente, para uso nos modelos\n",
    "Dep_Var_SKATER = data_aveiro_skater_Robust[\"Log_P_A\"].astype(float)\n",
    "\n",
    "# Criação de dataframe com variáveis independente, para uso nos modelos\n",
    "Ind_Var_SKATER = data_aveiro_skater_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"Zona_SKATER_1.0\",\n",
    "        \"Zona_SKATER_2.0\",\n",
    "        \"Zona_SKATER_3.0\",\n",
    "        \"Zona_SKATER_4.0\",\n",
    "        \"Zona_SKATER_5.0\",\n",
    "        \"Zona_SKATER_6.0\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_lag_SKATER_lagX = data_aveiro_skater_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"Zona_SKATER_1.0\",\n",
    "        \"Zona_SKATER_2.0\",\n",
    "        \"Zona_SKATER_3.0\",\n",
    "        \"Zona_SKATER_4.0\",\n",
    "        \"Zona_SKATER_5.0\",\n",
    "        \"Zona_SKATER_6.0\",\n",
    "        \"MCA_1_lag\",\n",
    "        \"MCA_2_lag\",\n",
    "        \"MCA_3_lag\",\n",
    "        \"MCA_4_lag\",\n",
    "        \"Tot_AL_lag\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_lag_SKATER_lagY = data_aveiro_skater_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"Zona_SKATER_1.0\",\n",
    "        \"Zona_SKATER_2.0\",\n",
    "        \"Zona_SKATER_3.0\",\n",
    "        \"Zona_SKATER_4.0\",\n",
    "        \"Zona_SKATER_5.0\",\n",
    "        \"Zona_SKATER_6.0\",\n",
    "        \"Log_P_A_lag\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_lag_SKATER_lagXY = data_aveiro_skater_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"Zona_SKATER_1.0\",\n",
    "        \"Zona_SKATER_2.0\",\n",
    "        \"Zona_SKATER_3.0\",\n",
    "        \"Zona_SKATER_4.0\",\n",
    "        \"Zona_SKATER_5.0\",\n",
    "        \"Zona_SKATER_6.0\",\n",
    "        \"Log_P_A_lag\",\n",
    "        \"MCA_1_lag\",\n",
    "        \"MCA_2_lag\",\n",
    "        \"MCA_3_lag\",\n",
    "        \"MCA_4_lag\",\n",
    "        \"Tot_AL_lag\",\n",
    "    ]\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_OLS_skater = spreg.OLS(\n",
    "    Dep_Var_SKATER.values,  # Dependent variable\n",
    "    Ind_Var_SKATER.values,  # Independent variable\n",
    "    name_y=\"Log_P_A\",  # Dependent variable name\n",
    "    name_x=list(Ind_Var_SKATER.columns),  # Independent variable name\n",
    "    w=w_Queen_skater,\n",
    "    spat_diag=True,\n",
    "    moran=True,\n",
    "    name_w=\"w_Queen\",\n",
    ")\n",
    "\n",
    "print(M_OLS_skater.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_skater_Robust[\"residuals_OLS\"] = M_OLS_skater.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data_aveiro_skater_Robust[\"residuals_OLS\"], bins=30, kde=True)\n",
    "plt.title(\"Distributions of residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardisation of the residuals (Z-scores)\n",
    "data_aveiro_skater_Robust[\"Z_Score_residuals_OLS\"] = stats.zscore(\n",
    "    data_aveiro_skater_Robust[\"residuals_OLS\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the data against the expected normal distribution.\n",
    "qqplot(data_aveiro_skater_Robust[\"Z_Score_residuals_OLS\"], line=\"s\")\n",
    "plt.title(\"Normal Q-Q plot of residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Map - Equal Intervals\n",
    "f, ax = plt.subplots(1, figsize=(8, 12))\n",
    "ax = data_aveiro_skater_Robust.plot(\n",
    "    column=\"Z_Score_residuals_OLS\",  # Data to plot\n",
    "    scheme=\"EqualInterval\",  # Classification scheme\n",
    "    cmap=\"bwr\",  # Color palette\n",
    "    edgecolor=\"k\",  # Borderline color\n",
    "    linewidth=0.1,  # Borderline width\n",
    "    legend=True,  # Add legend\n",
    "    legend_kwds={\"fmt\": \"{:.1f}\"},  # Remove decimals in legend (for legibility)\n",
    "    k=10,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"residuals_OLS\")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Map - Equal Intervals\n",
    "f, ax = plt.subplots(1, figsize=(8, 12))\n",
    "ax = data_aveiro_skater_Robust.plot(\n",
    "    column=\"Z_Score_residuals_OLS\",  # Data to plot\n",
    "    scheme=\"StdMean\",  # Classification scheme\n",
    "    cmap=\"bwr\",  # Color palette\n",
    "    edgecolor=\"k\",  # Borderline color\n",
    "    linewidth=0.1,  # Borderline width\n",
    "    legend=True,  # Add legend\n",
    "    legend_kwds={\n",
    "        \"fmt\": \"{:.1f}\",\n",
    "        \"loc\": \"lower right\",\n",
    "    },  # Remove decimals in legend (for legibility)\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"residuals_OLS\")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Linear Regressions (Aveiro) - FR (Freguesias)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Preparation for DID Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to geodataframe\n",
    "data_aveiro_fr = gpd.GeoDataFrame(all_data_fr, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_fr,\n",
    "    values=\"Cluster_LP\",\n",
    "    index=[\"FR11\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data_aveiro_fr.plot(\n",
    "    column=\"FR11\", categorical=True, legend=True, figsize=(10, 10), cmap=\"tab20\"\n",
    ")\n",
    "cx.add_basemap(ax, crs=data_aveiro_fr.crs, source=cx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply above list to data\n",
    "data_aveiro_fr[\"D\"] = np.where((data_aveiro_fr[\"FR11\"] == 12), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr[\"D\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check areas defined as control and intervention areas (D=0 and D=1)\n",
    "ax = data_aveiro_fr.plot(\n",
    "    column=data_aveiro_fr[\"D\"],\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    figsize=(10, 10),\n",
    "    cmap=\"tab20\",\n",
    ")\n",
    "cx.add_basemap(ax, crs=data_aveiro_fr.crs, source=cx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Linear Regression (focused in Aveiro Center - Freguesias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate DT (true when both D and T are equal to 1)\n",
    "data_aveiro_fr[\"DT\"] = data_aveiro_fr[\"D\"] * data_aveiro_fr[\"T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr[\"DT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr[\"D\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for skater zones\n",
    "data_aveiro_fr_ols = pd.get_dummies(\n",
    "    data_aveiro_fr, columns=[\"FR11\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_ols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "c_y_eur_area_fr = data_aveiro_fr_ols[\"Log_P_A\"].astype(float)\n",
    "\n",
    "c_X_eur_area_fr = data_aveiro_fr_ols[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"TAA\",\n",
    "        \"FR11_5\",\n",
    "        \"FR11_6\",\n",
    "        \"FR11_10\",\n",
    "        \"FR11_12\",\n",
    "        \"FR11_13\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "# removido IPI - VIF elevado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model for casasapo with log of price per square meter as dependent variable\n",
    "c_X_eur_area_fr = sm.add_constant(c_X_eur_area_fr)\n",
    "model_c_eur_area_fr = sm.OLS(c_y_eur_area_fr, c_X_eur_area_fr)\n",
    "results_c_eur_area_fr = model_c_eur_area_fr.fit()\n",
    "fr_save = results_c_eur_area_fr.summary2()\n",
    "results_c_eur_area_fr.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export results to csv\n",
    "# fr_save.tables[0].to_csv('fr_0.csv')\n",
    "# fr_save.tables[1].to_csv('fr_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostics for the model\n",
    "cls = Linear_Reg_Diagnostic(results_c_eur_area_fr)\n",
    "fig, ax = cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = results_c_eur_area_fr.outlier_test()\n",
    "# print('Bad data points (bonf(p) < 0.05):')\n",
    "# test[test['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers = test[test['bonf(p)'] < 0.05].index.values\n",
    "# outliers_sum=outliers_sum+list(outliers)\n",
    "# all_data.loc[list(outliers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Difference in Difference validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data for the model (DID validation)\n",
    "data_aveiro_fr_DID = data_aveiro_fr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_DID[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_DID = data_aveiro_fr_DID[data_aveiro_fr_DID[\"T\"] == 0]\n",
    "data_aveiro_fr_DID[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_aveiro_fr_DID[\"Year\"].unique():\n",
    "    data_aveiro_fr_DID[\"Year\" + str(i)] = np.where(\n",
    "        data_aveiro_fr_DID[\"Year\"] == i, data_aveiro_fr_DID[\"D\"], 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_DID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_fr_DID,\n",
    "    values=\"Log_P_A\",\n",
    "    index=[\"FR11\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ").head(10)\n",
    "# não incluir cluster 102 e 106, por escassez de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for FR11 zones\n",
    "data_aveiro_fr_DID = pd.get_dummies(\n",
    "    data_aveiro_fr_DID, columns=[\"FR11\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dependent variable and independent variables\n",
    "DID_y_eur_area_fr = data_aveiro_fr_DID[\"Log_P_A\"].astype(float)\n",
    "\n",
    "DID_X_eur_area_fr = data_aveiro_fr_DID[\n",
    "    [\n",
    "        \"Year2006.0\",\n",
    "        \"Year2007.0\",\n",
    "        \"Year2008.0\",\n",
    "        \"Year2009.0\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"Tot_AL\",\n",
    "        \"IPI\",\n",
    "        \"TAA\",\n",
    "        \"FR11_5\",\n",
    "        \"FR11_6\",\n",
    "        \"FR11_10\",\n",
    "        \"FR11_12\",\n",
    "        \"FR11_13\",\n",
    "    ]\n",
    "].astype(float)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model\n",
    "DID_X_eur_area_fr = sm.add_constant(DID_X_eur_area_fr)\n",
    "model_DID_eur_area_fr = sm.OLS(DID_y_eur_area_fr, DID_X_eur_area_fr)\n",
    "results_DID_eur_area_fr = model_DID_eur_area_fr.fit()\n",
    "DID_fr_save = results_DID_eur_area_fr.summary2()\n",
    "results_DID_eur_area_fr.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export results to csv\n",
    "# DID_fr_save.tables[0].to_csv('DID_fr_0.csv')\n",
    "# DID_fr_save.tables[1].to_csv('DID_fr_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostics for the model\n",
    "cls = Linear_Reg_Diagnostic(results_DID_eur_area_fr)\n",
    "fig, ax = cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = results_DID_eur_area_fr.outlier_test()\n",
    "# print('Bad data points (bonf(p) < 0.05):')\n",
    "# test[test['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers = test[test['bonf(p)'] < 0.05].index.values\n",
    "# outliers_sum=outliers_sum+list(outliers)\n",
    "# all_data.loc[list(outliers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Spatial Linear Regression (focused in Aveiro Center - FR11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust = data_aveiro_fr.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração da matriz W, a partir do subset, usando a de matriz de contiguidade Queen\n",
    "w_Queen_fr = weights.contiguity.Queen.from_dataframe(data_aveiro_fr_Robust)\n",
    "# Standardização das linhas\n",
    "w_Queen_fr.transform = \"R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma resultante da metodologia matriz Queen para pesos espaciais\n",
    "pd.Series(w_Queen_fr.cardinalities).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_Queen_fr.mean_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # image saved - this function is heavy and slows down the notebook\n",
    "# plot_spatial_weights(w_Queen_fr, data_aveiro_fr_Robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data_aveiro_fr_Robust.plot(\n",
    "    column=\"FR11\", categorical=True, legend=True, figsize=(10, 10), cmap=\"tab20c\"\n",
    ")\n",
    "cx.add_basemap(\n",
    "    ax, crs=data_aveiro_fr_Robust.crs, source=cx.providers.OpenStreetMap.Mapnik\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply above list to data\n",
    "data_aveiro_fr_Robust[\"D\"] = np.where((data_aveiro_fr_Robust[\"FR11\"] == 12), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust[\"D\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_aveiro_fr_Robust[\"D\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate DT (true when both D and T are equal to 1)\n",
    "data_aveiro_fr_Robust[\"DT\"] = data_aveiro_fr_Robust[\"D\"] * data_aveiro_fr_Robust[\"T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust[\"DT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust[\"MCA_1_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_fr, data_aveiro_fr_Robust[\"MCA_1\"]\n",
    ")\n",
    "data_aveiro_fr_Robust[\"MCA_2_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_fr, data_aveiro_fr_Robust[\"MCA_2\"]\n",
    ")\n",
    "data_aveiro_fr_Robust[\"MCA_3_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_fr, data_aveiro_fr_Robust[\"MCA_3\"]\n",
    ")\n",
    "data_aveiro_fr_Robust[\"MCA_4_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_fr, data_aveiro_fr_Robust[\"MCA_4\"]\n",
    ")\n",
    "data_aveiro_fr_Robust[\"Tot_AL_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_fr, data_aveiro_fr_Robust[\"Tot_AL\"]\n",
    ")\n",
    "data_aveiro_fr_Robust[\"Log_P_A_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_skater, data_aveiro_fr_Robust[\"Log_P_A\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for skater zones\n",
    "data_aveiro_fr_Robust = pd.get_dummies(\n",
    "    data_aveiro_fr_Robust, columns=[\"FR11\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de dataframe com variável dependente, para uso nos modelos\n",
    "Dep_Var_FR = data_aveiro_fr_Robust[\"Log_P_A\"].astype(float)\n",
    "\n",
    "# Criação de dataframe com variáveis independente, para uso nos modelos\n",
    "Ind_Var_FR = data_aveiro_fr_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"FR11_5\",\n",
    "        \"FR11_6\",\n",
    "        \"FR11_10\",\n",
    "        \"FR11_12\",\n",
    "        \"FR11_13\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_FR_lagX = data_aveiro_fr_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"FR11_5\",\n",
    "        \"FR11_6\",\n",
    "        \"FR11_10\",\n",
    "        \"FR11_12\",\n",
    "        \"FR11_13\",\n",
    "        \"MCA_1_lag\",\n",
    "        \"MCA_2_lag\",\n",
    "        \"MCA_3_lag\",\n",
    "        \"MCA_4_lag\",\n",
    "        \"Tot_AL_lag\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_FR_lagY = data_aveiro_fr_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"FR11_5\",\n",
    "        \"FR11_6\",\n",
    "        \"FR11_10\",\n",
    "        \"FR11_12\",\n",
    "        \"FR11_13\",\n",
    "        \"Log_P_A_lag\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_FR_lagXY = data_aveiro_fr_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"FR11_5\",\n",
    "        \"FR11_6\",\n",
    "        \"FR11_10\",\n",
    "        \"FR11_12\",\n",
    "        \"FR11_13\",\n",
    "        \"Log_P_A_lag\",\n",
    "        \"MCA_1_lag\",\n",
    "        \"MCA_2_lag\",\n",
    "        \"MCA_3_lag\",\n",
    "        \"MCA_4_lag\",\n",
    "        \"Tot_AL_lag\",\n",
    "    ]\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_OLS_FR = spreg.OLS(\n",
    "    Dep_Var_FR.values,  # Dependent variable\n",
    "    Ind_Var_FR.values,  # Independent variable\n",
    "    name_y=\"Log_P_A\",  # Dependent variable name\n",
    "    name_x=list(Ind_Var_FR.columns),  # Independent variable name\n",
    "    w=w_Queen_fr,\n",
    "    spat_diag=True,\n",
    "    moran=True,\n",
    "    name_w=\"w_Queen\",\n",
    ")\n",
    "\n",
    "print(M_OLS_FR.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_fr_Robust[\"residuals_OLS\"] = M_OLS_FR.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data_aveiro_fr_Robust[\"residuals_OLS\"], bins=30, kde=True)\n",
    "plt.title(\"Distributions of residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardisation of the residuals (Z-scores)\n",
    "data_aveiro_fr_Robust[\"Z_Score_residuals_OLS\"] = stats.zscore(\n",
    "    data_aveiro_fr_Robust[\"residuals_OLS\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the data against the expected normal distribution.\n",
    "qqplot(data_aveiro_fr_Robust[\"Z_Score_residuals_OLS\"], line=\"s\")\n",
    "plt.title(\"Normal Q-Q plot of residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Map - Equal Intervals\n",
    "f, ax = plt.subplots(1, figsize=(8, 12))\n",
    "ax = data_aveiro_fr_Robust.plot(\n",
    "    column=\"Z_Score_residuals_OLS\",  # Data to plot\n",
    "    scheme=\"EqualInterval\",  # Classification scheme\n",
    "    cmap=\"bwr\",  # Color palette\n",
    "    edgecolor=\"k\",  # Borderline color\n",
    "    linewidth=0.1,  # Borderline width\n",
    "    legend=True,  # Add legend\n",
    "    legend_kwds={\"fmt\": \"{:.1f}\"},  # Remove decimals in legend (for legibility)\n",
    "    k=10,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"residuals_OLS\")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Map - Equal Intervals\n",
    "f, ax = plt.subplots(1, figsize=(8, 12))\n",
    "ax = data_aveiro_fr_Robust.plot(\n",
    "    column=\"Z_Score_residuals_OLS\",  # Data to plot\n",
    "    scheme=\"StdMean\",  # Classification scheme\n",
    "    cmap=\"bwr\",  # Color palette\n",
    "    edgecolor=\"k\",  # Borderline color\n",
    "    linewidth=0.1,  # Borderline width\n",
    "    legend=True,  # Add legend\n",
    "    legend_kwds={\n",
    "        \"fmt\": \"{:.1f}\",\n",
    "        \"loc\": \"lower right\",\n",
    "    },  # Remove decimals in legend (for legibility)\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"residuals_OLS\")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Linear Regressions (Aveiro) - LP\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Data Preparation for DID Linear Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform data to geodataframe\n",
    "data_aveiro_LP = gpd.GeoDataFrame(all_data_LP, geometry=\"geometry\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view Zona_SKATER clusters\n",
    "ax = data_aveiro_LP.plot(\n",
    "    figsize=(10, 20),\n",
    "    column=data_aveiro_LP[\"Cluster_LP\"],\n",
    "    categorical=True,\n",
    "    edgecolor=\"w\",\n",
    "    legend=False,\n",
    "    linewidth=0.2,\n",
    "    cmap=\"tab20\",\n",
    ")\n",
    "cx.add_basemap(ax, crs=data_aveiro_LP.crs, source=cx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Area de Intervenção, a ser considerada D = 1\n",
    "lista_D1 = [\n",
    "    19,\n",
    "    22,\n",
    "    31,\n",
    "    40,\n",
    "    41,\n",
    "    42,\n",
    "    80,\n",
    "    102,\n",
    "    105,\n",
    "    107,\n",
    "    109,\n",
    "    110,\n",
    "    156,\n",
    "    159,\n",
    "    160,\n",
    "    161,\n",
    "    165,\n",
    "    166,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lista de zonas na fronteira D1/D0:\n",
    "# 26, 57, 101, 103, 104, 111, 155, 161, 165"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP[\"D\"] = np.where(data_aveiro_LP[\"Cluster_LP\"].isin(lista_D1), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view Zona_SKATER clusters\n",
    "ax = data_aveiro_LP.plot(\n",
    "    figsize=(10, 10),\n",
    "    column=data_aveiro_LP[\"D\"],\n",
    "    linewidth=0.2,\n",
    "    categorical=True,\n",
    "    legend=True,\n",
    "    cmap=\"tab20\",\n",
    ")\n",
    "cx.add_basemap(ax, crs=data_aveiro_LP.crs, source=cx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check no. of dwellings per cluster in Aveiro Center\n",
    "pd.pivot_table(\n",
    "    data_aveiro_LP,\n",
    "    values=\"Log_P_A\",\n",
    "    index=[\"Cluster_LP\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ").head(10)\n",
    "# não incluir cluster 80, 102 e 106, por escassez de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP.to_pickle(\"../Data/data_aveiro_LP.piclo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP[\"D\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_aveiro_LP[\"D\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate DT (true when both D and T are equal to 1)\n",
    "data_aveiro_LP[\"DT\"] = data_aveiro_LP[\"D\"] * data_aveiro_LP[\"T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP[\"DT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check log_P_A distribution in the territory\n",
    "ax = data_aveiro_LP.plot(\n",
    "    column=data_aveiro_LP[\"Log_P_A\"], legend=True, figsize=(10, 10), cmap=\"viridis\"\n",
    ")\n",
    "cx.add_basemap(ax, crs=data_aveiro_LP.crs, source=cx.providers.OpenStreetMap.Mapnik)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Linear Regression (focused in Aveiro Center - LP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_LP,\n",
    "    values=\"Log_P_A\",\n",
    "    index=[\"Cluster_LP\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_LP, values=\"Cluster_LP\", index=[\"D\"], aggfunc=lambda x: len(x.unique())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for LP zones\n",
    "data_aveiro_LP_ols = pd.get_dummies(\n",
    "    data_aveiro_LP, columns=[\"Cluster_LP\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_ols.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "c_y_eur_area_LP = data_aveiro_LP_ols[\"Log_P_A\"].astype(float)\n",
    "\n",
    "c_X_eur_area_LP = data_aveiro_LP_ols[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"TAA\",\n",
    "        \"Cluster_LP_5.0\",\n",
    "        \"Cluster_LP_13.0\",\n",
    "        \"Cluster_LP_14.0\",\n",
    "        \"Cluster_LP_18.0\",\n",
    "        \"Cluster_LP_19.0\",\n",
    "        \"Cluster_LP_20.0\",\n",
    "        \"Cluster_LP_21.0\",\n",
    "        \"Cluster_LP_22.0\",\n",
    "        \"Cluster_LP_24.0\",\n",
    "        \"Cluster_LP_25.0\",\n",
    "        \"Cluster_LP_26.0\",\n",
    "        \"Cluster_LP_27.0\",\n",
    "        \"Cluster_LP_28.0\",\n",
    "        \"Cluster_LP_29.0\",\n",
    "        \"Cluster_LP_30.0\",\n",
    "        \"Cluster_LP_31.0\",\n",
    "        \"Cluster_LP_37.0\",\n",
    "        \"Cluster_LP_38.0\",\n",
    "        \"Cluster_LP_39.0\",\n",
    "        \"Cluster_LP_40.0\",\n",
    "        \"Cluster_LP_41.0\",\n",
    "        \"Cluster_LP_42.0\",\n",
    "        \"Cluster_LP_43.0\",\n",
    "        \"Cluster_LP_45.0\",\n",
    "        \"Cluster_LP_57.0\",\n",
    "        \"Cluster_LP_58.0\",\n",
    "        \"Cluster_LP_59.0\",\n",
    "        \"Cluster_LP_60.0\",\n",
    "        \"Cluster_LP_63.0\",\n",
    "        \"Cluster_LP_64.0\",\n",
    "        \"Cluster_LP_65.0\",\n",
    "        \"Cluster_LP_66.0\",\n",
    "        \"Cluster_LP_67.0\",\n",
    "        \"Cluster_LP_80.0\",\n",
    "        \"Cluster_LP_82.0\",\n",
    "        \"Cluster_LP_85.0\",\n",
    "        \"Cluster_LP_89.0\",\n",
    "        \"Cluster_LP_90.0\",\n",
    "        \"Cluster_LP_91.0\",\n",
    "        \"Cluster_LP_100.0\",\n",
    "        \"Cluster_LP_101.0\",\n",
    "        \"Cluster_LP_102.0\",\n",
    "        \"Cluster_LP_103.0\",\n",
    "        \"Cluster_LP_104.0\",\n",
    "        \"Cluster_LP_105.0\",\n",
    "        \"Cluster_LP_107.0\",\n",
    "        \"Cluster_LP_108.0\",\n",
    "        \"Cluster_LP_109.0\",\n",
    "        \"Cluster_LP_110.0\",\n",
    "        \"Cluster_LP_111.0\",\n",
    "        \"Cluster_LP_124.0\",\n",
    "        \"Cluster_LP_125.0\",\n",
    "        \"Cluster_LP_129.0\",\n",
    "        \"Cluster_LP_150.0\",\n",
    "        \"Cluster_LP_151.0\",\n",
    "        \"Cluster_LP_152.0\",\n",
    "        \"Cluster_LP_153.0\",\n",
    "        \"Cluster_LP_154.0\",\n",
    "        \"Cluster_LP_155.0\",\n",
    "        \"Cluster_LP_156.0\",\n",
    "        \"Cluster_LP_157.0\",\n",
    "        \"Cluster_LP_158.0\",\n",
    "        \"Cluster_LP_159.0\",\n",
    "        \"Cluster_LP_160.0\",\n",
    "        \"Cluster_LP_161.0\",\n",
    "        \"Cluster_LP_162.0\",\n",
    "        \"Cluster_LP_163.0\",\n",
    "        \"Cluster_LP_164.0\",\n",
    "        \"Cluster_LP_165.0\",\n",
    "        \"Cluster_LP_166.0\",\n",
    "    ]\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear model for casasapo with log of price per square meter as dependent variable\n",
    "c_X_eur_area_LP = sm.add_constant(c_X_eur_area_LP)\n",
    "model_c_eur_area_LP = sm.OLS(c_y_eur_area_LP, c_X_eur_area_LP)\n",
    "results_c_eur_area_LP = model_c_eur_area_LP.fit()\n",
    "lp_save = results_c_eur_area_LP.summary2()\n",
    "results_c_eur_area_LP.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export results to csv\n",
    "# lp_save.tables[0].to_csv('lp_0.csv')\n",
    "# lp_save.tables[1].to_csv('lp_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostics for the model\n",
    "cls = Linear_Reg_Diagnostic(results_c_eur_area_LP)\n",
    "fig, ax = cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = results_c_eur_area_LP.outlier_test()\n",
    "# print('Bad data points (bonf(p) < 0.05):')\n",
    "# test[test['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers = test[test['bonf(p)'] < 0.05].index.values\n",
    "# outliers_sum=outliers_sum+list(outliers)\n",
    "# all_data.loc[list(outliers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Difference in Difference validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data for the model (DID validation)\n",
    "data_aveiro_LP_DID = data_aveiro_LP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_DID[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_DID = data_aveiro_LP_DID[data_aveiro_LP_DID[\"T\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_DID[\"Year\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data_aveiro_LP_DID[\"Year\"].unique():\n",
    "    data_aveiro_LP_DID[\"Year\" + str(i)] = np.where(\n",
    "        data_aveiro_LP_DID[\"Year\"] == i, data_aveiro_LP_DID[\"D\"], 0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_DID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of dwellings per cluster\n",
    "pd.pivot_table(\n",
    "    data_aveiro_LP_DID,\n",
    "    values=\"Log_P_A\",\n",
    "    index=[\"Cluster_LP\"],\n",
    "    aggfunc=lambda x: len(x.unique()),\n",
    ").head(10)\n",
    "# não incluir cluster 102 e 106, por escassez de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for LP zones\n",
    "data_aveiro_LP_DID = pd.get_dummies(\n",
    "    data_aveiro_LP_DID, columns=[\"Cluster_LP\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_DID.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dependent variable and independent variables\n",
    "DID_y_eur_area_LP = data_aveiro_LP_DID[\"Log_P_A\"].astype(float)\n",
    "\n",
    "DID_X_eur_area_LP = data_aveiro_LP_DID[\n",
    "    [\n",
    "        \"Year2006.0\",\n",
    "        \"Year2007.0\",\n",
    "        \"Year2008.0\",\n",
    "        \"Year2009.0\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"TAA\",\n",
    "        \"Cluster_LP_5.0\",\n",
    "        \"Cluster_LP_13.0\",\n",
    "        \"Cluster_LP_14.0\",\n",
    "        \"Cluster_LP_18.0\",\n",
    "        \"Cluster_LP_19.0\",\n",
    "        \"Cluster_LP_20.0\",\n",
    "        \"Cluster_LP_21.0\",\n",
    "        \"Cluster_LP_22.0\",\n",
    "        \"Cluster_LP_24.0\",\n",
    "        \"Cluster_LP_25.0\",\n",
    "        \"Cluster_LP_26.0\",\n",
    "        \"Cluster_LP_27.0\",\n",
    "        \"Cluster_LP_28.0\",\n",
    "        \"Cluster_LP_29.0\",\n",
    "        \"Cluster_LP_30.0\",\n",
    "        \"Cluster_LP_31.0\",\n",
    "        \"Cluster_LP_37.0\",\n",
    "        \"Cluster_LP_38.0\",\n",
    "        \"Cluster_LP_39.0\",\n",
    "        \"Cluster_LP_40.0\",\n",
    "        \"Cluster_LP_41.0\",\n",
    "        \"Cluster_LP_42.0\",\n",
    "        \"Cluster_LP_43.0\",\n",
    "        \"Cluster_LP_45.0\",\n",
    "        \"Cluster_LP_58.0\",\n",
    "        \"Cluster_LP_59.0\",\n",
    "        \"Cluster_LP_60.0\",\n",
    "        \"Cluster_LP_63.0\",\n",
    "        \"Cluster_LP_64.0\",\n",
    "        \"Cluster_LP_65.0\",\n",
    "        \"Cluster_LP_67.0\",\n",
    "        \"Cluster_LP_82.0\",\n",
    "        \"Cluster_LP_85.0\",\n",
    "        \"Cluster_LP_89.0\",\n",
    "        \"Cluster_LP_91.0\",\n",
    "        \"Cluster_LP_100.0\",\n",
    "        \"Cluster_LP_101.0\",\n",
    "        \"Cluster_LP_104.0\",\n",
    "        \"Cluster_LP_105.0\",\n",
    "        \"Cluster_LP_109.0\",\n",
    "        \"Cluster_LP_111.0\",\n",
    "        \"Cluster_LP_124.0\",\n",
    "        \"Cluster_LP_150.0\",\n",
    "        \"Cluster_LP_151.0\",\n",
    "        \"Cluster_LP_152.0\",\n",
    "        \"Cluster_LP_153.0\",\n",
    "        \"Cluster_LP_154.0\",\n",
    "        \"Cluster_LP_155.0\",\n",
    "        \"Cluster_LP_156.0\",\n",
    "        \"Cluster_LP_157.0\",\n",
    "        \"Cluster_LP_158.0\",\n",
    "        \"Cluster_LP_159.0\",\n",
    "        \"Cluster_LP_160.0\",\n",
    "        \"Cluster_LP_161.0\",\n",
    "        \"Cluster_LP_162.0\",\n",
    "        \"Cluster_LP_163.0\",\n",
    "        \"Cluster_LP_164.0\",\n",
    "        \"Cluster_LP_166.0\",\n",
    "    ]\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the model\n",
    "DID_X_eur_area_LP = sm.add_constant(DID_X_eur_area_LP)\n",
    "model_DID_eur_area_LP = sm.OLS(DID_y_eur_area_LP, DID_X_eur_area_LP)\n",
    "results_DID_eur_area_LP = model_DID_eur_area_LP.fit()\n",
    "DID_lp_save = results_DID_eur_area_LP.summary2()\n",
    "results_DID_eur_area_LP.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export results to csv\n",
    "# DID_lp_save.tables[0].to_csv('DID_lp_0.csv')\n",
    "# DID_lp_save.tables[1].to_csv('DID_lp_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot diagnostics for the model\n",
    "cls = Linear_Reg_Diagnostic(results_DID_eur_area_LP)\n",
    "fig, ax = cls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = results_DID_eur_area_LP.outlier_test()\n",
    "# print('Bad data points (bonf(p) < 0.05):')\n",
    "# test[test['bonf(p)'] < 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outliers = test[test['bonf(p)'] < 0.05].index.values\n",
    "# outliers_sum=outliers_sum+list(outliers)\n",
    "# all_data.loc[list(outliers)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Spatial Linear Regression (focused in Aveiro Center - LP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust = data_aveiro_LP.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geração da matriz W, a partir do subset, usando a de matriz de contiguidade Queen\n",
    "w_Queen_LP = weights.contiguity.Queen.from_dataframe(data_aveiro_LP_Robust)\n",
    "# Standardização das linhas\n",
    "w_Queen_LP.transform = \"R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma resultante da metodologia matriz Queen para pesos espaciais\n",
    "pd.Series(w_Queen_LP.cardinalities).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_Queen_LP.mean_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image saved - this function is heavy and slows down the notebook\n",
    "# plot_spatial_weights(w_Queen_LP, data_aveiro_LP_Robust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = data_aveiro_LP_Robust.plot(\n",
    "    column=\"Cluster_LP\", categorical=True, legend=True, figsize=(10, 20), cmap=\"tab20c\"\n",
    ")\n",
    "cx.add_basemap(\n",
    "    ax, crs=data_aveiro_LP_Robust.crs, source=cx.providers.OpenStreetMap.Mapnik\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust[\"D\"] = np.where(\n",
    "    data_aveiro_LP_Robust[\"Cluster_LP\"].isin(lista_D1), 1, 0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust[\"D\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_aveiro_LP_Robust[\"D\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate DT (true when both D and T are equal to 1)\n",
    "data_aveiro_LP_Robust[\"DT\"] = data_aveiro_LP_Robust[\"D\"] * data_aveiro_LP_Robust[\"T\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust[\"DT\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(data_aveiro_LP_Robust[\"DT\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies for skater zones\n",
    "data_aveiro_LP_Robust = pd.get_dummies(\n",
    "    data_aveiro_LP_Robust, columns=[\"Cluster_LP\"], drop_first=True, dtype=float\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust[\"MCA_1_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_LP, data_aveiro_LP_Robust[\"MCA_1\"]\n",
    ")\n",
    "\n",
    "data_aveiro_LP_Robust[\"MCA_2_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_LP, data_aveiro_LP_Robust[\"MCA_2\"]\n",
    ")\n",
    "\n",
    "data_aveiro_LP_Robust[\"MCA_3_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_LP, data_aveiro_LP_Robust[\"MCA_3\"]\n",
    ")\n",
    "\n",
    "data_aveiro_LP_Robust[\"MCA_4_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_LP, data_aveiro_LP_Robust[\"MCA_4\"]\n",
    ")\n",
    "\n",
    "data_aveiro_LP_Robust[\"Tot_AL_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_LP, data_aveiro_LP_Robust[\"Tot_AL\"]\n",
    ")\n",
    "\n",
    "data_aveiro_LP_Robust[\"Log_P_A_lag\"] = weights.lag_spatial(\n",
    "    w_Queen_LP, data_aveiro_LP_Robust[\"Log_P_A\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de dataframe com variável dependente, para uso nos modelos\n",
    "Dep_Var_LP = data_aveiro_LP_Robust[\"Log_P_A\"].astype(float)\n",
    "\n",
    "# Criação de dataframe com variáveis independente, para uso nos modelos\n",
    "Ind_Var_LP = data_aveiro_LP_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"Cluster_LP_5.0\",\n",
    "        \"Cluster_LP_13.0\",\n",
    "        \"Cluster_LP_14.0\",\n",
    "        \"Cluster_LP_18.0\",\n",
    "        \"Cluster_LP_19.0\",\n",
    "        \"Cluster_LP_20.0\",\n",
    "        \"Cluster_LP_21.0\",\n",
    "        \"Cluster_LP_22.0\",\n",
    "        \"Cluster_LP_24.0\",\n",
    "        \"Cluster_LP_25.0\",\n",
    "        \"Cluster_LP_26.0\",\n",
    "        \"Cluster_LP_27.0\",\n",
    "        \"Cluster_LP_28.0\",\n",
    "        \"Cluster_LP_29.0\",\n",
    "        \"Cluster_LP_30.0\",\n",
    "        \"Cluster_LP_31.0\",\n",
    "        \"Cluster_LP_37.0\",\n",
    "        \"Cluster_LP_38.0\",\n",
    "        \"Cluster_LP_39.0\",\n",
    "        \"Cluster_LP_40.0\",\n",
    "        \"Cluster_LP_41.0\",\n",
    "        \"Cluster_LP_42.0\",\n",
    "        \"Cluster_LP_43.0\",\n",
    "        \"Cluster_LP_45.0\",\n",
    "        \"Cluster_LP_57.0\",\n",
    "        \"Cluster_LP_58.0\",\n",
    "        \"Cluster_LP_59.0\",\n",
    "        \"Cluster_LP_60.0\",\n",
    "        \"Cluster_LP_63.0\",\n",
    "        \"Cluster_LP_64.0\",\n",
    "        \"Cluster_LP_65.0\",\n",
    "        \"Cluster_LP_66.0\",\n",
    "        \"Cluster_LP_67.0\",\n",
    "        \"Cluster_LP_80.0\",\n",
    "        \"Cluster_LP_82.0\",\n",
    "        \"Cluster_LP_85.0\",\n",
    "        \"Cluster_LP_89.0\",\n",
    "        \"Cluster_LP_90.0\",\n",
    "        \"Cluster_LP_91.0\",\n",
    "        \"Cluster_LP_100.0\",\n",
    "        \"Cluster_LP_101.0\",\n",
    "        \"Cluster_LP_102.0\",\n",
    "        \"Cluster_LP_103.0\",\n",
    "        \"Cluster_LP_104.0\",\n",
    "        \"Cluster_LP_105.0\",\n",
    "        \"Cluster_LP_107.0\",\n",
    "        \"Cluster_LP_108.0\",\n",
    "        \"Cluster_LP_109.0\",\n",
    "        \"Cluster_LP_110.0\",\n",
    "        \"Cluster_LP_111.0\",\n",
    "        \"Cluster_LP_124.0\",\n",
    "        \"Cluster_LP_125.0\",\n",
    "        \"Cluster_LP_129.0\",\n",
    "        \"Cluster_LP_150.0\",\n",
    "        \"Cluster_LP_151.0\",\n",
    "        \"Cluster_LP_152.0\",\n",
    "        \"Cluster_LP_154.0\",\n",
    "        \"Cluster_LP_155.0\",\n",
    "        \"Cluster_LP_156.0\",\n",
    "        \"Cluster_LP_157.0\",\n",
    "        \"Cluster_LP_158.0\",\n",
    "        \"Cluster_LP_159.0\",\n",
    "        \"Cluster_LP_160.0\",\n",
    "        \"Cluster_LP_161.0\",\n",
    "        \"Cluster_LP_163.0\",\n",
    "        \"Cluster_LP_164.0\",\n",
    "        \"Cluster_LP_165.0\",\n",
    "        \"Cluster_LP_166.0\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_LP_lagX = data_aveiro_LP_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"Cluster_LP_5.0\",\n",
    "        \"Cluster_LP_13.0\",\n",
    "        \"Cluster_LP_14.0\",\n",
    "        \"Cluster_LP_18.0\",\n",
    "        \"Cluster_LP_19.0\",\n",
    "        \"Cluster_LP_20.0\",\n",
    "        \"Cluster_LP_21.0\",\n",
    "        \"Cluster_LP_22.0\",\n",
    "        \"Cluster_LP_24.0\",\n",
    "        \"Cluster_LP_25.0\",\n",
    "        \"Cluster_LP_26.0\",\n",
    "        \"Cluster_LP_27.0\",\n",
    "        \"Cluster_LP_28.0\",\n",
    "        \"Cluster_LP_29.0\",\n",
    "        \"Cluster_LP_30.0\",\n",
    "        \"Cluster_LP_31.0\",\n",
    "        \"Cluster_LP_37.0\",\n",
    "        \"Cluster_LP_38.0\",\n",
    "        \"Cluster_LP_39.0\",\n",
    "        \"Cluster_LP_40.0\",\n",
    "        \"Cluster_LP_41.0\",\n",
    "        \"Cluster_LP_42.0\",\n",
    "        \"Cluster_LP_43.0\",\n",
    "        \"Cluster_LP_45.0\",\n",
    "        \"Cluster_LP_57.0\",\n",
    "        \"Cluster_LP_58.0\",\n",
    "        \"Cluster_LP_59.0\",\n",
    "        \"Cluster_LP_60.0\",\n",
    "        \"Cluster_LP_63.0\",\n",
    "        \"Cluster_LP_64.0\",\n",
    "        \"Cluster_LP_65.0\",\n",
    "        \"Cluster_LP_66.0\",\n",
    "        \"Cluster_LP_67.0\",\n",
    "        \"Cluster_LP_80.0\",\n",
    "        \"Cluster_LP_82.0\",\n",
    "        \"Cluster_LP_85.0\",\n",
    "        \"Cluster_LP_89.0\",\n",
    "        \"Cluster_LP_90.0\",\n",
    "        \"Cluster_LP_91.0\",\n",
    "        \"Cluster_LP_100.0\",\n",
    "        \"Cluster_LP_101.0\",\n",
    "        \"Cluster_LP_102.0\",\n",
    "        \"Cluster_LP_103.0\",\n",
    "        \"Cluster_LP_104.0\",\n",
    "        \"Cluster_LP_105.0\",\n",
    "        \"Cluster_LP_107.0\",\n",
    "        \"Cluster_LP_108.0\",\n",
    "        \"Cluster_LP_109.0\",\n",
    "        \"Cluster_LP_110.0\",\n",
    "        \"Cluster_LP_111.0\",\n",
    "        \"Cluster_LP_124.0\",\n",
    "        \"Cluster_LP_125.0\",\n",
    "        \"Cluster_LP_129.0\",\n",
    "        \"Cluster_LP_150.0\",\n",
    "        \"Cluster_LP_151.0\",\n",
    "        \"Cluster_LP_152.0\",\n",
    "        \"Cluster_LP_154.0\",\n",
    "        \"Cluster_LP_155.0\",\n",
    "        \"Cluster_LP_156.0\",\n",
    "        \"Cluster_LP_157.0\",\n",
    "        \"Cluster_LP_158.0\",\n",
    "        \"Cluster_LP_159.0\",\n",
    "        \"Cluster_LP_160.0\",\n",
    "        \"Cluster_LP_161.0\",\n",
    "        \"Cluster_LP_163.0\",\n",
    "        \"Cluster_LP_164.0\",\n",
    "        \"Cluster_LP_165.0\",\n",
    "        \"Cluster_LP_166.0\",\n",
    "        \"MCA_1_lag\",\n",
    "        \"MCA_2_lag\",\n",
    "        \"MCA_3_lag\",\n",
    "        \"MCA_4_lag\",\n",
    "        \"Tot_AL_lag\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_LP_lagY = data_aveiro_LP_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"Cluster_LP_5.0\",\n",
    "        \"Cluster_LP_13.0\",\n",
    "        \"Cluster_LP_14.0\",\n",
    "        \"Cluster_LP_18.0\",\n",
    "        \"Cluster_LP_19.0\",\n",
    "        \"Cluster_LP_20.0\",\n",
    "        \"Cluster_LP_21.0\",\n",
    "        \"Cluster_LP_22.0\",\n",
    "        \"Cluster_LP_24.0\",\n",
    "        \"Cluster_LP_25.0\",\n",
    "        \"Cluster_LP_26.0\",\n",
    "        \"Cluster_LP_27.0\",\n",
    "        \"Cluster_LP_28.0\",\n",
    "        \"Cluster_LP_29.0\",\n",
    "        \"Cluster_LP_30.0\",\n",
    "        \"Cluster_LP_31.0\",\n",
    "        \"Cluster_LP_37.0\",\n",
    "        \"Cluster_LP_38.0\",\n",
    "        \"Cluster_LP_39.0\",\n",
    "        \"Cluster_LP_40.0\",\n",
    "        \"Cluster_LP_41.0\",\n",
    "        \"Cluster_LP_42.0\",\n",
    "        \"Cluster_LP_43.0\",\n",
    "        \"Cluster_LP_45.0\",\n",
    "        \"Cluster_LP_57.0\",\n",
    "        \"Cluster_LP_58.0\",\n",
    "        \"Cluster_LP_59.0\",\n",
    "        \"Cluster_LP_60.0\",\n",
    "        \"Cluster_LP_63.0\",\n",
    "        \"Cluster_LP_64.0\",\n",
    "        \"Cluster_LP_65.0\",\n",
    "        \"Cluster_LP_66.0\",\n",
    "        \"Cluster_LP_67.0\",\n",
    "        \"Cluster_LP_80.0\",\n",
    "        \"Cluster_LP_82.0\",\n",
    "        \"Cluster_LP_85.0\",\n",
    "        \"Cluster_LP_89.0\",\n",
    "        \"Cluster_LP_90.0\",\n",
    "        \"Cluster_LP_91.0\",\n",
    "        \"Cluster_LP_100.0\",\n",
    "        \"Cluster_LP_101.0\",\n",
    "        \"Cluster_LP_102.0\",\n",
    "        \"Cluster_LP_103.0\",\n",
    "        \"Cluster_LP_104.0\",\n",
    "        \"Cluster_LP_105.0\",\n",
    "        \"Cluster_LP_107.0\",\n",
    "        \"Cluster_LP_108.0\",\n",
    "        \"Cluster_LP_109.0\",\n",
    "        \"Cluster_LP_110.0\",\n",
    "        \"Cluster_LP_111.0\",\n",
    "        \"Cluster_LP_124.0\",\n",
    "        \"Cluster_LP_125.0\",\n",
    "        \"Cluster_LP_129.0\",\n",
    "        \"Cluster_LP_150.0\",\n",
    "        \"Cluster_LP_151.0\",\n",
    "        \"Cluster_LP_152.0\",\n",
    "        \"Cluster_LP_154.0\",\n",
    "        \"Cluster_LP_155.0\",\n",
    "        \"Cluster_LP_156.0\",\n",
    "        \"Cluster_LP_157.0\",\n",
    "        \"Cluster_LP_158.0\",\n",
    "        \"Cluster_LP_159.0\",\n",
    "        \"Cluster_LP_160.0\",\n",
    "        \"Cluster_LP_161.0\",\n",
    "        \"Cluster_LP_163.0\",\n",
    "        \"Cluster_LP_164.0\",\n",
    "        \"Cluster_LP_165.0\",\n",
    "        \"Cluster_LP_166.0\",\n",
    "        \"Log_P_A_lag\",\n",
    "    ]\n",
    "].astype(float)\n",
    "\n",
    "Ind_Var_LP_lagXY = data_aveiro_LP_Robust[\n",
    "    [\n",
    "        \"DT\",\n",
    "        \"MCA_1\",\n",
    "        \"MCA_2\",\n",
    "        \"MCA_3\",\n",
    "        \"MCA_4\",\n",
    "        \"TAA\",\n",
    "        \"IPI\",\n",
    "        \"Tot_AL\",\n",
    "        \"Cluster_LP_5.0\",\n",
    "        \"Cluster_LP_13.0\",\n",
    "        \"Cluster_LP_14.0\",\n",
    "        \"Cluster_LP_18.0\",\n",
    "        \"Cluster_LP_19.0\",\n",
    "        \"Cluster_LP_20.0\",\n",
    "        \"Cluster_LP_21.0\",\n",
    "        \"Cluster_LP_22.0\",\n",
    "        \"Cluster_LP_24.0\",\n",
    "        \"Cluster_LP_25.0\",\n",
    "        \"Cluster_LP_26.0\",\n",
    "        \"Cluster_LP_27.0\",\n",
    "        \"Cluster_LP_28.0\",\n",
    "        \"Cluster_LP_29.0\",\n",
    "        \"Cluster_LP_30.0\",\n",
    "        \"Cluster_LP_31.0\",\n",
    "        \"Cluster_LP_37.0\",\n",
    "        \"Cluster_LP_38.0\",\n",
    "        \"Cluster_LP_39.0\",\n",
    "        \"Cluster_LP_40.0\",\n",
    "        \"Cluster_LP_41.0\",\n",
    "        \"Cluster_LP_42.0\",\n",
    "        \"Cluster_LP_43.0\",\n",
    "        \"Cluster_LP_45.0\",\n",
    "        \"Cluster_LP_57.0\",\n",
    "        \"Cluster_LP_58.0\",\n",
    "        \"Cluster_LP_59.0\",\n",
    "        \"Cluster_LP_60.0\",\n",
    "        \"Cluster_LP_63.0\",\n",
    "        \"Cluster_LP_64.0\",\n",
    "        \"Cluster_LP_65.0\",\n",
    "        \"Cluster_LP_66.0\",\n",
    "        \"Cluster_LP_67.0\",\n",
    "        \"Cluster_LP_80.0\",\n",
    "        \"Cluster_LP_82.0\",\n",
    "        \"Cluster_LP_85.0\",\n",
    "        \"Cluster_LP_89.0\",\n",
    "        \"Cluster_LP_90.0\",\n",
    "        \"Cluster_LP_91.0\",\n",
    "        \"Cluster_LP_100.0\",\n",
    "        \"Cluster_LP_101.0\",\n",
    "        \"Cluster_LP_102.0\",\n",
    "        \"Cluster_LP_103.0\",\n",
    "        \"Cluster_LP_104.0\",\n",
    "        \"Cluster_LP_105.0\",\n",
    "        \"Cluster_LP_107.0\",\n",
    "        \"Cluster_LP_108.0\",\n",
    "        \"Cluster_LP_109.0\",\n",
    "        \"Cluster_LP_110.0\",\n",
    "        \"Cluster_LP_111.0\",\n",
    "        \"Cluster_LP_124.0\",\n",
    "        \"Cluster_LP_125.0\",\n",
    "        \"Cluster_LP_129.0\",\n",
    "        \"Cluster_LP_150.0\",\n",
    "        \"Cluster_LP_151.0\",\n",
    "        \"Cluster_LP_152.0\",\n",
    "        \"Cluster_LP_154.0\",\n",
    "        \"Cluster_LP_155.0\",\n",
    "        \"Cluster_LP_156.0\",\n",
    "        \"Cluster_LP_157.0\",\n",
    "        \"Cluster_LP_158.0\",\n",
    "        \"Cluster_LP_159.0\",\n",
    "        \"Cluster_LP_160.0\",\n",
    "        \"Cluster_LP_161.0\",\n",
    "        \"Cluster_LP_163.0\",\n",
    "        \"Cluster_LP_164.0\",\n",
    "        \"Cluster_LP_165.0\",\n",
    "        \"Cluster_LP_166.0\",\n",
    "        \"Log_P_A_lag\",\n",
    "        \"MCA_1_lag\",\n",
    "        \"MCA_2_lag\",\n",
    "        \"MCA_3_lag\",\n",
    "        \"MCA_4_lag\",\n",
    "        \"Tot_AL_lag\",\n",
    "    ]\n",
    "].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_OLS_LP = spreg.OLS(\n",
    "    Dep_Var_LP.values,  # Dependent variable\n",
    "    Ind_Var_LP.values,  # Independent variable\n",
    "    name_y=\"Log_P_A\",  # Dependent variable name\n",
    "    name_x=list(Ind_Var_LP.columns),  # Independent variable name\n",
    "    w=w_Queen_LP,\n",
    "    spat_diag=True,\n",
    "    moran=True,\n",
    "    name_w=\"w_Queen\",\n",
    ")\n",
    "\n",
    "print(M_OLS_LP.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aveiro_LP_Robust[\"residuals_OLS\"] = M_OLS_LP.u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data_aveiro_LP_Robust[\"residuals_OLS\"], bins=30, kde=True)\n",
    "plt.title(\"Distributions of residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardisation of the residuals (Z-scores)\n",
    "data_aveiro_LP_Robust[\"Z_Score_residuals_OLS\"] = stats.zscore(\n",
    "    data_aveiro_LP_Robust[\"residuals_OLS\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of the data against the expected normal distribution.\n",
    "qqplot(data_aveiro_LP_Robust[\"Z_Score_residuals_OLS\"], line=\"s\")\n",
    "plt.title(\"Normal Q-Q plot of residuals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Map - Equal Intervals\n",
    "f, ax = plt.subplots(1, figsize=(8, 12))\n",
    "ax = data_aveiro_LP_Robust.plot(\n",
    "    column=\"Z_Score_residuals_OLS\",  # Data to plot\n",
    "    scheme=\"EqualInterval\",  # Classification scheme\n",
    "    cmap=\"bwr\",  # Color palette\n",
    "    edgecolor=\"k\",  # Borderline color\n",
    "    linewidth=0.1,  # Borderline width\n",
    "    legend=True,  # Add legend\n",
    "    legend_kwds={\"fmt\": \"{:.1f}\"},  # Remove decimals in legend (for legibility)\n",
    "    k=10,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"residuals_OLS\")\n",
    "ax.set_axis_off()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Map - Equal Intervals\n",
    "f, ax = plt.subplots(1, figsize=(8, 12))\n",
    "ax = data_aveiro_LP_Robust.plot(\n",
    "    column=\"Z_Score_residuals_OLS\",  # Data to plot\n",
    "    scheme=\"StdMean\",  # Classification scheme\n",
    "    cmap=\"bwr\",  # Color palette\n",
    "    edgecolor=\"k\",  # Borderline color\n",
    "    linewidth=0.1,  # Borderline width\n",
    "    legend=True,  # Add legend\n",
    "    legend_kwds={\n",
    "        \"fmt\": \"{:.1f}\",\n",
    "        \"loc\": \"lower right\",\n",
    "    },  # Remove decimals in legend (for legibility)\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "ax.set_title(\"residuals_OLS\")\n",
    "ax.set_axis_off()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
